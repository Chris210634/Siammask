{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c65794c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# SiamMask\n",
    "# Licensed under The MIT License\n",
    "# Written by Qiang Wang (wangqiang2015 at ia.ac.cn)\n",
    "# --------------------------------------------------------\n",
    "from __future__ import division\n",
    "import argparse\n",
    "import logging\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from os import makedirs\n",
    "from os.path import join, isdir, isfile\n",
    "\n",
    "from utils.log_helper import init_log, add_file_handler\n",
    "from utils.load_helper import load_pretrain\n",
    "from utils.bbox_helper import get_axis_aligned_bbox, cxy_wh_2_rect\n",
    "from utils.benchmark_helper import load_dataset, dataset_zoo\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from utils.anchors import Anchors\n",
    "from utils.tracker_config import TrackerConfig\n",
    "\n",
    "from utils.config_helper import load_config\n",
    "from utils.pyvotkit.region import vot_overlap, vot_float2str\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "thrs = np.arange(0.3, 0.5, 0.05)\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Test SiamMask')\n",
    "parser.add_argument('--arch', dest='arch', default='', choices=['Custom',],\n",
    "                    help='architecture of pretrained model')\n",
    "parser.add_argument('--config', dest='config', required=True, help='hyper-parameter for SiamMask')\n",
    "parser.add_argument('--resume', default='', type=str, required=True,\n",
    "                    metavar='PATH', help='path to latest checkpoint (default: none)')\n",
    "parser.add_argument('--mask', action='store_true', help='whether use mask output')\n",
    "parser.add_argument('--refine', action='store_true', help='whether use mask refine output')\n",
    "parser.add_argument('--dataset', dest='dataset', default='VOT2018', choices=dataset_zoo,\n",
    "                    help='datasets')\n",
    "parser.add_argument('-l', '--log', default=\"log_test.txt\", type=str, help='log file')\n",
    "parser.add_argument('-v', '--visualization', dest='visualization', action='store_true',\n",
    "                    help='whether visualize result')\n",
    "parser.add_argument('--save_mask', action='store_true', help='whether use save mask for davis')\n",
    "parser.add_argument('--gt', action='store_true', help='whether use gt rect for davis (Oracle)')\n",
    "parser.add_argument('--video', default='', type=str, help='test special video')\n",
    "parser.add_argument('--cpu', action='store_true', help='cpu mode')\n",
    "parser.add_argument('--debug', action='store_true', help='debug mode')\n",
    "\n",
    "\n",
    "def to_torch(ndarray):\n",
    "    if type(ndarray).__module__ == 'numpy':\n",
    "        return torch.from_numpy(ndarray)\n",
    "    elif not torch.is_tensor(ndarray):\n",
    "        raise ValueError(\"Cannot convert {} to torch tensor\"\n",
    "                         .format(type(ndarray)))\n",
    "    return ndarray\n",
    "\n",
    "\n",
    "def im_to_torch(img):\n",
    "    img = np.transpose(img, (2, 0, 1))  # C*H*W\n",
    "    img = to_torch(img).float()\n",
    "    return img\n",
    "\n",
    "\n",
    "def get_subwindow_tracking(im, pos, model_sz, original_sz, avg_chans, out_mode='torch'):\n",
    "    if isinstance(pos, float):\n",
    "        pos = [pos, pos]\n",
    "    sz = original_sz\n",
    "    im_sz = im.shape\n",
    "    c = (original_sz + 1) / 2\n",
    "    context_xmin = round(pos[0] - c)\n",
    "    context_xmax = context_xmin + sz - 1\n",
    "    context_ymin = round(pos[1] - c)\n",
    "    context_ymax = context_ymin + sz - 1\n",
    "    left_pad = int(max(0., -context_xmin))\n",
    "    top_pad = int(max(0., -context_ymin))\n",
    "    right_pad = int(max(0., context_xmax - im_sz[1] + 1))\n",
    "    bottom_pad = int(max(0., context_ymax - im_sz[0] + 1))\n",
    "\n",
    "    context_xmin = context_xmin + left_pad\n",
    "    context_xmax = context_xmax + left_pad\n",
    "    context_ymin = context_ymin + top_pad\n",
    "    context_ymax = context_ymax + top_pad\n",
    "\n",
    "    # zzp: a more easy speed version\n",
    "    r, c, k = im.shape\n",
    "    if any([top_pad, bottom_pad, left_pad, right_pad]):\n",
    "        te_im = np.zeros((r + top_pad + bottom_pad, c + left_pad + right_pad, k), np.uint8)\n",
    "        te_im[top_pad:top_pad + r, left_pad:left_pad + c, :] = im\n",
    "        if top_pad:\n",
    "            te_im[0:top_pad, left_pad:left_pad + c, :] = avg_chans\n",
    "        if bottom_pad:\n",
    "            te_im[r + top_pad:, left_pad:left_pad + c, :] = avg_chans\n",
    "        if left_pad:\n",
    "            te_im[:, 0:left_pad, :] = avg_chans\n",
    "        if right_pad:\n",
    "            te_im[:, c + left_pad:, :] = avg_chans\n",
    "        im_patch_original = te_im[int(context_ymin):int(context_ymax + 1), int(context_xmin):int(context_xmax + 1), :]\n",
    "    else:\n",
    "        im_patch_original = im[int(context_ymin):int(context_ymax + 1), int(context_xmin):int(context_xmax + 1), :]\n",
    "\n",
    "    if not np.array_equal(model_sz, original_sz):\n",
    "        im_patch = cv2.resize(im_patch_original, (model_sz, model_sz))\n",
    "    else:\n",
    "        im_patch = im_patch_original\n",
    "    # cv2.imshow('crop', im_patch)\n",
    "    # cv2.waitKey(0)\n",
    "    return im_to_torch(im_patch) if out_mode in 'torch' else im_patch\n",
    "\n",
    "\n",
    "def generate_anchor(cfg, score_size):\n",
    "    anchors = Anchors(cfg)\n",
    "    anchor = anchors.anchors\n",
    "    x1, y1, x2, y2 = anchor[:, 0], anchor[:, 1], anchor[:, 2], anchor[:, 3]\n",
    "    anchor = np.stack([(x1+x2)*0.5, (y1+y2)*0.5, x2-x1, y2-y1], 1)\n",
    "\n",
    "    total_stride = anchors.stride\n",
    "    anchor_num = anchor.shape[0]\n",
    "\n",
    "    anchor = np.tile(anchor, score_size * score_size).reshape((-1, 4))\n",
    "    ori = - (score_size // 2) * total_stride\n",
    "    xx, yy = np.meshgrid([ori + total_stride * dx for dx in range(score_size)],\n",
    "                         [ori + total_stride * dy for dy in range(score_size)])\n",
    "    xx, yy = np.tile(xx.flatten(), (anchor_num, 1)).flatten(), \\\n",
    "             np.tile(yy.flatten(), (anchor_num, 1)).flatten()\n",
    "    anchor[:, 0], anchor[:, 1] = xx.astype(np.float32), yy.astype(np.float32)\n",
    "    return anchor\n",
    "\n",
    "\n",
    "def siamese_init(im, target_pos, target_sz, model, hp=None, device='cpu'):\n",
    "    state = dict()\n",
    "    state['im_h'] = im.shape[0]\n",
    "    state['im_w'] = im.shape[1]\n",
    "    p = TrackerConfig()\n",
    "    p.update(hp, model.anchors)\n",
    "\n",
    "    p.renew()\n",
    "\n",
    "    net = model\n",
    "    p.scales = model.anchors['scales']\n",
    "    p.ratios = model.anchors['ratios']\n",
    "    p.anchor_num = model.anchor_num\n",
    "    p.anchor = generate_anchor(model.anchors, p.score_size)\n",
    "    avg_chans = np.mean(im, axis=(0, 1))\n",
    "\n",
    "    wc_z = target_sz[0] + p.context_amount * sum(target_sz)\n",
    "    hc_z = target_sz[1] + p.context_amount * sum(target_sz)\n",
    "    s_z = round(np.sqrt(wc_z * hc_z))\n",
    "    # initialize the exemplar\n",
    "    z_crop = get_subwindow_tracking(im, target_pos, p.exemplar_size, s_z, avg_chans)\n",
    "\n",
    "    z = Variable(z_crop.unsqueeze(0))\n",
    "    net.template(z.to(device))\n",
    "\n",
    "    if p.windowing == 'cosine':\n",
    "        window = np.outer(np.hanning(p.score_size), np.hanning(p.score_size))\n",
    "    elif p.windowing == 'uniform':\n",
    "        window = np.ones((p.score_size, p.score_size))\n",
    "    window = np.tile(window.flatten(), p.anchor_num)\n",
    "\n",
    "    state['p'] = p\n",
    "    state['net'] = net\n",
    "    state['avg_chans'] = avg_chans\n",
    "    state['window'] = window\n",
    "    state['target_pos'] = target_pos\n",
    "    state['target_sz'] = target_sz\n",
    "    return state\n",
    "\n",
    "\n",
    "def siamese_track(state, im, i, mask_enable=False, refine_enable=False, device='cpu', debug=False):\n",
    "    p = state['p']\n",
    "    net = state['net']\n",
    "    avg_chans = state['avg_chans']\n",
    "    window = state['window']\n",
    "    target_pos = state['target_pos']\n",
    "    target_sz = state['target_sz']\n",
    "\n",
    "    wc_x = target_sz[1] + p.context_amount * sum(target_sz)\n",
    "    hc_x = target_sz[0] + p.context_amount * sum(target_sz)\n",
    "    s_x = np.sqrt(wc_x * hc_x)\n",
    "    scale_x = p.exemplar_size / s_x\n",
    "    d_search = (p.instance_size - p.exemplar_size) / 2\n",
    "    pad = d_search / scale_x\n",
    "    s_x = s_x + 2 * pad\n",
    "    crop_box = [target_pos[0] - round(s_x) / 2, target_pos[1] - round(s_x) / 2, round(s_x), round(s_x)]\n",
    "\n",
    "    if debug:\n",
    "        im_debug = im.copy()\n",
    "        crop_box_int = np.int0(crop_box)\n",
    "        cv2.rectangle(im_debug, (crop_box_int[0], crop_box_int[1]),\n",
    "                      (crop_box_int[0] + crop_box_int[2], crop_box_int[1] + crop_box_int[3]), (255, 0, 0), 2)\n",
    "        cv2.imshow('search area', im_debug)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "    # extract scaled crops for search region x at previous target position\n",
    "    x_crop = Variable(get_subwindow_tracking(im, target_pos, p.instance_size, round(s_x), avg_chans).unsqueeze(0))\n",
    "\n",
    "    if mask_enable:\n",
    "        score, delta, mask = net.track_mask(x_crop.to(device))\n",
    "    else:\n",
    "        score, delta = net.track(x_crop.to(device))\n",
    "\n",
    "    delta = delta.permute(1, 2, 3, 0).contiguous().view(4, -1).data.cpu().numpy()\n",
    "    score = F.softmax(score.permute(1, 2, 3, 0).contiguous().view(2, -1).permute(1, 0), dim=1).data[:,\n",
    "            1].cpu().numpy()\n",
    "\n",
    "    delta[0, :] = delta[0, :] * p.anchor[:, 2] + p.anchor[:, 0]\n",
    "    delta[1, :] = delta[1, :] * p.anchor[:, 3] + p.anchor[:, 1]\n",
    "    delta[2, :] = np.exp(delta[2, :]) * p.anchor[:, 2]\n",
    "    delta[3, :] = np.exp(delta[3, :]) * p.anchor[:, 3]\n",
    "\n",
    "    def change(r):\n",
    "        return np.maximum(r, 1. / r)\n",
    "\n",
    "    def sz(w, h):\n",
    "        pad = (w + h) * 0.5\n",
    "        sz2 = (w + pad) * (h + pad)\n",
    "        return np.sqrt(sz2)\n",
    "\n",
    "    def sz_wh(wh):\n",
    "        pad = (wh[0] + wh[1]) * 0.5\n",
    "        sz2 = (wh[0] + pad) * (wh[1] + pad)\n",
    "        return np.sqrt(sz2)\n",
    "\n",
    "    # size penalty\n",
    "    target_sz_in_crop = target_sz*scale_x\n",
    "    s_c = change(sz(delta[2, :], delta[3, :]) / (sz_wh(target_sz_in_crop)))  # scale penalty\n",
    "    r_c = change((target_sz_in_crop[0] / target_sz_in_crop[1]) / (delta[2, :] / delta[3, :]))  # ratio penalty\n",
    "\n",
    "    penalty = np.exp(-(r_c * s_c - 1) * p.penalty_k)\n",
    "    pscore = penalty * score\n",
    "\n",
    "    # cos window (motion model)\n",
    "    pscore = pscore * (1 - p.window_influence) + window * p.window_influence\n",
    "    #best_pscore_id = np.argmax(pscore)\n",
    "    \n",
    "    best_pscore_id = pscore.argsort()[-i]\n",
    "\n",
    "    pred_in_crop = delta[:, best_pscore_id] / scale_x\n",
    "    lr = penalty[best_pscore_id] * score[best_pscore_id] * p.lr  # lr for OTB\n",
    "\n",
    "    res_x = pred_in_crop[0] + target_pos[0]\n",
    "    res_y = pred_in_crop[1] + target_pos[1]\n",
    "\n",
    "    res_w = target_sz[0] * (1 - lr) + pred_in_crop[2] * lr\n",
    "    res_h = target_sz[1] * (1 - lr) + pred_in_crop[3] * lr\n",
    "\n",
    "    target_pos = np.array([res_x, res_y])\n",
    "    target_sz = np.array([res_w, res_h])\n",
    "\n",
    "    # for Mask Branch\n",
    "    if mask_enable:\n",
    "        best_pscore_id_mask = np.unravel_index(best_pscore_id, (5, p.score_size, p.score_size))\n",
    "        delta_x, delta_y = best_pscore_id_mask[2], best_pscore_id_mask[1]\n",
    "\n",
    "        if refine_enable:\n",
    "            mask = net.track_refine((delta_y, delta_x)).to(device).sigmoid().squeeze().view(\n",
    "                p.out_size, p.out_size).cpu().data.numpy()\n",
    "        else:\n",
    "            mask = mask[0, :, delta_y, delta_x].sigmoid(). \\\n",
    "                squeeze().view(p.out_size, p.out_size).cpu().data.numpy()\n",
    "\n",
    "        def crop_back(image, bbox, out_sz, padding=-1):\n",
    "            a = (out_sz[0] - 1) / bbox[2]\n",
    "            b = (out_sz[1] - 1) / bbox[3]\n",
    "            c = -a * bbox[0]\n",
    "            d = -b * bbox[1]\n",
    "            mapping = np.array([[a, 0, c],\n",
    "                                [0, b, d]]).astype(np.float)\n",
    "            crop = cv2.warpAffine(image, mapping, (out_sz[0], out_sz[1]),\n",
    "                                  flags=cv2.INTER_LINEAR,\n",
    "                                  borderMode=cv2.BORDER_CONSTANT,\n",
    "                                  borderValue=padding)\n",
    "            return crop\n",
    "\n",
    "        s = crop_box[2] / p.instance_size\n",
    "        sub_box = [crop_box[0] + (delta_x - p.base_size / 2) * p.total_stride * s,\n",
    "                   crop_box[1] + (delta_y - p.base_size / 2) * p.total_stride * s,\n",
    "                   s * p.exemplar_size, s * p.exemplar_size]\n",
    "        s = p.out_size / sub_box[2]\n",
    "        back_box = [-sub_box[0] * s, -sub_box[1] * s, state['im_w'] * s, state['im_h'] * s]\n",
    "        mask_in_img = crop_back(mask, back_box, (state['im_w'], state['im_h']))\n",
    "\n",
    "        target_mask = (mask_in_img > p.seg_thr).astype(np.uint8)\n",
    "        if cv2.__version__[-5] == '4':\n",
    "            contours, _ = cv2.findContours(target_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "        else:\n",
    "            _, contours, _ = cv2.findContours(target_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "        cnt_area = [cv2.contourArea(cnt) for cnt in contours]\n",
    "        if len(contours) != 0 and np.max(cnt_area) > 100:\n",
    "            contour = contours[np.argmax(cnt_area)]  # use max area polygon\n",
    "            polygon = contour.reshape(-1, 2)\n",
    "            # pbox = cv2.boundingRect(polygon)  # Min Max Rectangle\n",
    "            prbox = cv2.boxPoints(cv2.minAreaRect(polygon))  # Rotated Rectangle\n",
    "\n",
    "            # box_in_img = pbox\n",
    "            rbox_in_img = prbox\n",
    "        else:  # empty mask\n",
    "            location = cxy_wh_2_rect(target_pos, target_sz)\n",
    "            rbox_in_img = np.array([[location[0], location[1]],\n",
    "                                    [location[0] + location[2], location[1]],\n",
    "                                    [location[0] + location[2], location[1] + location[3]],\n",
    "                                    [location[0], location[1] + location[3]]])\n",
    "\n",
    "    target_pos[0] = max(0, min(state['im_w'], target_pos[0]))\n",
    "    target_pos[1] = max(0, min(state['im_h'], target_pos[1]))\n",
    "    target_sz[0] = max(10, min(state['im_w'], target_sz[0]))\n",
    "    target_sz[1] = max(10, min(state['im_h'], target_sz[1]))\n",
    "\n",
    "    state['target_pos'] = target_pos\n",
    "    state['target_sz'] = target_sz\n",
    "    state['score'] = score[best_pscore_id]\n",
    "    state['mask'] = mask_in_img if mask_enable else []\n",
    "    state['ploygon'] = rbox_in_img if mask_enable else []\n",
    "    return state\n",
    "\n",
    "\n",
    "def track_vot(model, video, hp=None, mask_enable=False, refine_enable=False, device='cpu'):\n",
    "    regions = []  # result and states[1 init / 2 lost / 0 skip]\n",
    "    image_files, gt = video['image_files'], video['gt']\n",
    "\n",
    "    start_frame, end_frame, lost_times, toc = 0, len(image_files), 0, 0\n",
    "\n",
    "    for f, image_file in enumerate(image_files):\n",
    "        im = cv2.imread(image_file)\n",
    "        #img2 = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        #plt.imshow(img2)\n",
    "        im_show = im.copy()\n",
    "        \n",
    "        tic = cv2.getTickCount()\n",
    "        for ii in range(1, 101,10):\n",
    "            if f == start_frame:  # init\n",
    "                cx, cy, w, h = get_axis_aligned_bbox(gt[f])\n",
    "                target_pos = np.array([cx, cy])\n",
    "                target_sz = np.array([w, h])\n",
    "                state = siamese_init(im, target_pos, target_sz, model, hp, device)  # init tracker\n",
    "                location = cxy_wh_2_rect(state['target_pos'], state['target_sz'])\n",
    "                regions.append(1 if 'VOT' in args.dataset else gt[f])\n",
    "            elif f > start_frame:  # tracking\n",
    "                state = siamese_track(state, im, ii, mask_enable, refine_enable, device, args.debug)  # track\n",
    "                if mask_enable:\n",
    "                    location = state['ploygon'].flatten()\n",
    "                    mask = state['mask']\n",
    "                else:\n",
    "                    location = cxy_wh_2_rect(state['target_pos'], state['target_sz'])\n",
    "                    mask = []\n",
    "\n",
    "                if 'VOT' in args.dataset:\n",
    "                    gt_polygon = ((gt[f][0], gt[f][1]), (gt[f][2], gt[f][3]),\n",
    "                                  (gt[f][4], gt[f][5]), (gt[f][6], gt[f][7]))\n",
    "                    if mask_enable:\n",
    "                        pred_polygon = ((location[0], location[1]), (location[2], location[3]),\n",
    "                                        (location[4], location[5]), (location[6], location[7]))\n",
    "                    else:\n",
    "                        pred_polygon = ((location[0], location[1]),\n",
    "                                        (location[0] + location[2], location[1]),\n",
    "                                        (location[0] + location[2], location[1] + location[3]),\n",
    "                                        (location[0], location[1] + location[3]))\n",
    "                    b_overlap = vot_overlap(gt_polygon, pred_polygon, (im.shape[1], im.shape[0]))\n",
    "                else:\n",
    "                    b_overlap = 1\n",
    "\n",
    "                if b_overlap:\n",
    "                    regions.append(location)\n",
    "                else:  # lost\n",
    "                    regions.append(2)\n",
    "                    lost_times += 1\n",
    "                    start_frame = f + 5  # skip 5 frames\n",
    "            else:  # skip\n",
    "                regions.append(0)\n",
    "            toc += cv2.getTickCount() - tic\n",
    "\n",
    "            #if args.visualization and f >= start_frame:  # visualization (skip lost frame)\n",
    "            if f >= start_frame:\n",
    "\n",
    "                if f == 0: cv2.destroyAllWindows()\n",
    "                if gt.shape[0] > f:\n",
    "                    if len(gt[f]) == 8:\n",
    "                        cv2.polylines(im_show, [np.array(gt[f], np.int).reshape((-1, 1, 2))], True, (0, 255, 0), 3)\n",
    "                        pass\n",
    "                    else:\n",
    "                        cv2.rectangle(im_show, (gt[f, 0], gt[f, 1]), (gt[f, 0] + gt[f, 2], gt[f, 1] + gt[f, 3]), (0, 255, 0), 3)\n",
    "                        pass\n",
    "                if len(location) == 8:\n",
    "                    if mask_enable:\n",
    "                        mask = mask > state['p'].seg_thr\n",
    "                        #im_show[:, :, 2] = mask * 255 + (1 - mask) * im_show[:, :, 2]\n",
    "                    location_int = np.int0(location)\n",
    "                    cv2.polylines(im_show, [location_int.reshape((-1, 1, 2))], True, (0, 255, 255), 3)\n",
    "                else:\n",
    "                    location = [int(l) for l in location]\n",
    "                    #cv2.rectangle(im_show, (location[0], location[1]),\n",
    "                     #             (location[0] + location[2], location[1] + location[3]), (0, 255, 255), 3)\n",
    "                #cv2.rectangle(im_show, (location[0], location[1]),\n",
    "                 #               (location[0] + location[2], location[1] + location[3]), (0, 255, 255), 3)\n",
    "        cv2.putText(im_show, str(f), (40, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "        cv2.putText(im_show, str(lost_times), (40, 80), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        cv2.putText(im_show, str(state['score']) if 'score' in state else '', (40, 120), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "        cv2.imshow(video['name'], im_show)\n",
    "        cv2.waitKey(1)\n",
    "            \n",
    "            \n",
    "    toc /= cv2.getTickFrequency()\n",
    "\n",
    "    # save result\n",
    "    name = args.arch.split('.')[0] + '_' + ('mask_' if mask_enable else '') + ('refine_' if refine_enable else '') +\\\n",
    "           args.resume.split('/')[-1].split('.')[0]\n",
    "\n",
    "    if 'VOT' in args.dataset:\n",
    "        video_path = join('test', args.dataset, name,\n",
    "                          'baseline', video['name'])\n",
    "        if not isdir(video_path): makedirs(video_path)\n",
    "        result_path = join(video_path, '{:s}_001.txt'.format(video['name']))\n",
    "        with open(result_path, \"w\") as fin:\n",
    "            for x in regions:\n",
    "                fin.write(\"{:d}\\n\".format(x)) if isinstance(x, int) else \\\n",
    "                        fin.write(','.join([vot_float2str(\"%.4f\", i) for i in x]) + '\\n')\n",
    "    else:  # OTB\n",
    "        video_path = join('test', args.dataset, name)\n",
    "        if not isdir(video_path): makedirs(video_path)\n",
    "        result_path = join(video_path, '{:s}.txt'.format(video['name']))\n",
    "        with open(result_path, \"w\") as fin:\n",
    "            for x in regions:\n",
    "                fin.write(','.join([str(i) for i in x])+'\\n')\n",
    "\n",
    "    logger.info('({:d}) Video: {:12s} Time: {:02.1f}s Speed: {:3.1f}fps Lost: {:d}'.format(\n",
    "        v_id, video['name'], toc, f / toc, lost_times))\n",
    "\n",
    "    return lost_times, f / toc\n",
    "\n",
    "\n",
    "def MultiBatchIouMeter(thrs, outputs, targets, start=None, end=None):\n",
    "    targets = np.array(targets)\n",
    "    outputs = np.array(outputs)\n",
    "\n",
    "    num_frame = targets.shape[0]\n",
    "    if start is None:\n",
    "        object_ids = np.array(list(range(outputs.shape[0]))) + 1\n",
    "    else:\n",
    "        object_ids = [int(id) for id in start]\n",
    "\n",
    "    num_object = len(object_ids)\n",
    "    res = np.zeros((num_object, len(thrs)), dtype=np.float32)\n",
    "\n",
    "    output_max_id = np.argmax(outputs, axis=0).astype('uint8')+1\n",
    "    outputs_max = np.max(outputs, axis=0)\n",
    "    for k, thr in enumerate(thrs):\n",
    "        output_thr = outputs_max > thr\n",
    "        for j in range(num_object):\n",
    "            target_j = targets == object_ids[j]\n",
    "\n",
    "            if start is None:\n",
    "                start_frame, end_frame = 1, num_frame - 1\n",
    "            else:\n",
    "                start_frame, end_frame = start[str(object_ids[j])] + 1, end[str(object_ids[j])] - 1\n",
    "            iou = []\n",
    "            for i in range(start_frame, end_frame):\n",
    "                pred = (output_thr[i] * output_max_id[i]) == (j+1)\n",
    "                mask_sum = (pred == 1).astype(np.uint8) + (target_j[i] > 0).astype(np.uint8)\n",
    "                intxn = np.sum(mask_sum == 2)\n",
    "                union = np.sum(mask_sum > 0)\n",
    "                if union > 0:\n",
    "                    iou.append(intxn / union)\n",
    "                elif union == 0 and intxn == 0:\n",
    "                    iou.append(1)\n",
    "            res[j, k] = np.mean(iou)\n",
    "    return res\n",
    "\n",
    "\n",
    "def track_vos(model, video, hp=None, mask_enable=False, refine_enable=False, mot_enable=False, device='cpu'):\n",
    "    image_files = video['image_files']\n",
    "\n",
    "    annos = [np.array(Image.open(x)) for x in video['anno_files']]\n",
    "    if 'anno_init_files' in video:\n",
    "        annos_init = [np.array(Image.open(x)) for x in video['anno_init_files']]\n",
    "    else:\n",
    "        annos_init = [annos[0]]\n",
    "\n",
    "    if not mot_enable:\n",
    "        annos = [(anno > 0).astype(np.uint8) for anno in annos]\n",
    "        annos_init = [(anno_init > 0).astype(np.uint8) for anno_init in annos_init]\n",
    "\n",
    "    if 'start_frame' in video:\n",
    "        object_ids = [int(id) for id in video['start_frame']]\n",
    "    else:\n",
    "        object_ids = [o_id for o_id in np.unique(annos[0]) if o_id != 0]\n",
    "        if len(object_ids) != len(annos_init):\n",
    "            annos_init = annos_init*len(object_ids)\n",
    "    object_num = len(object_ids)\n",
    "    toc = 0\n",
    "    pred_masks = np.zeros((object_num, len(image_files), annos[0].shape[0], annos[0].shape[1]))-1\n",
    "    for obj_id, o_id in enumerate(object_ids):\n",
    "\n",
    "        if 'start_frame' in video:\n",
    "            start_frame = video['start_frame'][str(o_id)]\n",
    "            end_frame = video['end_frame'][str(o_id)]\n",
    "        else:\n",
    "            start_frame, end_frame = 0, len(image_files)\n",
    "\n",
    "        for f, image_file in enumerate(image_files):\n",
    "            im = cv2.imread(image_file)\n",
    "            tic = cv2.getTickCount()\n",
    "            if f == start_frame:  # init\n",
    "                mask = annos_init[obj_id] == o_id\n",
    "                x, y, w, h = cv2.boundingRect((mask).astype(np.uint8))\n",
    "                cx, cy = x + w/2, y + h/2\n",
    "                target_pos = np.array([cx, cy])\n",
    "                target_sz = np.array([w, h])\n",
    "                state = siamese_init(im, target_pos, target_sz, model, hp, device=device)  # init tracker\n",
    "            elif end_frame >= f > start_frame:  # tracking\n",
    "                state = siamese_track(state, im, mask_enable, refine_enable, device=device)  # track\n",
    "                mask = state['mask']\n",
    "            toc += cv2.getTickCount() - tic\n",
    "            if end_frame >= f >= start_frame:\n",
    "                pred_masks[obj_id, f, :, :] = mask\n",
    "    toc /= cv2.getTickFrequency()\n",
    "\n",
    "    if len(annos) == len(image_files):\n",
    "        multi_mean_iou = MultiBatchIouMeter(thrs, pred_masks, annos,\n",
    "                                            start=video['start_frame'] if 'start_frame' in video else None,\n",
    "                                            end=video['end_frame'] if 'end_frame' in video else None)\n",
    "        for i in range(object_num):\n",
    "            for j, thr in enumerate(thrs):\n",
    "                logger.info('Fusion Multi Object{:20s} IOU at {:.2f}: {:.4f}'.format(video['name'] + '_' + str(i + 1), thr,\n",
    "                                                                           multi_mean_iou[i, j]))\n",
    "    else:\n",
    "        multi_mean_iou = []\n",
    "\n",
    "    if args.save_mask:\n",
    "        video_path = join('test', args.dataset, 'SiamMask', video['name'])\n",
    "        if not isdir(video_path): makedirs(video_path)\n",
    "        pred_mask_final = np.array(pred_masks)\n",
    "        pred_mask_final = (np.argmax(pred_mask_final, axis=0).astype('uint8') + 1) * (\n",
    "                np.max(pred_mask_final, axis=0) > state['p'].seg_thr).astype('uint8')\n",
    "        for i in range(pred_mask_final.shape[0]):\n",
    "            cv2.imwrite(join(video_path, image_files[i].split('/')[-1].split('.')[0] + '.png'), pred_mask_final[i].astype(np.uint8))\n",
    "\n",
    "    if args.visualization:\n",
    "        pred_mask_final = np.array(pred_masks)\n",
    "        pred_mask_final = (np.argmax(pred_mask_final, axis=0).astype('uint8') + 1) * (\n",
    "                np.max(pred_mask_final, axis=0) > state['p'].seg_thr).astype('uint8')\n",
    "        COLORS = np.random.randint(128, 255, size=(object_num, 3), dtype=\"uint8\")\n",
    "        COLORS = np.vstack([[0, 0, 0], COLORS]).astype(\"uint8\")\n",
    "        mask = COLORS[pred_mask_final]\n",
    "        for f, image_file in enumerate(image_files):\n",
    "            output = ((0.4 * cv2.imread(image_file)) + (0.6 * mask[f,:,:,:])).astype(\"uint8\")\n",
    "            cv2.imshow(\"mask\", output)\n",
    "            cv2.waitKey(1)\n",
    "\n",
    "    logger.info('({:d}) Video: {:12s} Time: {:02.1f}s Speed: {:3.1f}fps'.format(\n",
    "        v_id, video['name'], toc, f*len(object_ids) / toc))\n",
    "\n",
    "    return multi_mean_iou, f*len(object_ids) / toc\n",
    "\n",
    "\n",
    "def main():\n",
    "    global args, logger, v_id\n",
    "    args = parser.parse_args()\n",
    "    cfg = load_config(args)\n",
    "\n",
    "    init_log('global', logging.INFO)\n",
    "    if args.log != \"\":\n",
    "        add_file_handler('global', args.log, logging.INFO)\n",
    "\n",
    "    logger = logging.getLogger('global')\n",
    "    logger.info(args)\n",
    "\n",
    "    # setup model\n",
    "    if args.arch == 'Custom':\n",
    "        from custom import Custom\n",
    "        model = Custom(anchors=cfg['anchors'])\n",
    "    else:\n",
    "        parser.error('invalid architecture: {}'.format(args.arch))\n",
    "\n",
    "    if args.resume:\n",
    "        assert isfile(args.resume), '{} is not a valid file'.format(args.resume)\n",
    "        model = load_pretrain(model, args.resume)\n",
    "    model.eval()\n",
    "    device = torch.device('cuda' if (torch.cuda.is_available() and not args.cpu) else 'cpu')\n",
    "    model = model.to(device)\n",
    "    # setup dataset\n",
    "    dataset = load_dataset(args.dataset)\n",
    "\n",
    "    # VOS or VOT?\n",
    "    if args.dataset in ['DAVIS2016', 'DAVIS2017', 'ytb_vos'] and args.mask:\n",
    "        vos_enable = True  # enable Mask output\n",
    "    else:\n",
    "        vos_enable = False\n",
    "\n",
    "    total_lost = 0  # VOT\n",
    "    iou_lists = []  # VOS\n",
    "    speed_list = []\n",
    "\n",
    "    for v_id, video in enumerate(dataset.keys(), start=1):\n",
    "        if args.video != '' and video != args.video:\n",
    "            continue\n",
    "\n",
    "        if vos_enable:\n",
    "            iou_list, speed = track_vos(model, dataset[video], cfg['hp'] if 'hp' in cfg.keys() else None,\n",
    "                                 args.mask, args.refine, args.dataset in ['DAVIS2017', 'ytb_vos'], device=device)\n",
    "            iou_lists.append(iou_list)\n",
    "        else:\n",
    "            lost, speed = track_vot(model, dataset[video], cfg['hp'] if 'hp' in cfg.keys() else None,\n",
    "                             args.mask, args.refine, device=device)\n",
    "            total_lost += lost\n",
    "        speed_list.append(speed)\n",
    "\n",
    "    # report final result\n",
    "    if vos_enable:\n",
    "        for thr, iou in zip(thrs, np.mean(np.concatenate(iou_lists), axis=0)):\n",
    "            logger.info('Segmentation Threshold {:.2f} mIoU: {:.3f}'.format(thr, iou))\n",
    "    else:\n",
    "        logger.info('Total Lost: {:d}'.format(total_lost))\n",
    "\n",
    "    logger.info('Mean Speed: {:.2f} FPS'.format(np.mean(speed_list)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "36f223c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args([\"--config\", \"/projectnb/ece601/cliao25/SiamMask/experiments/siammask_base/config.json\",\n",
    "                          \"--resume\", \"/projectnb/ece601/cliao25/SiamMask/experiments/siammask_base/snapshot/checkpoint_e15.pth\",\n",
    "                          \"--mask\", \"--dataset\", \"VOT2018\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "53a70aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = load_config(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c69ca9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-04-21 11:59:45,016-rk0-features.py# 66] Current training 0 layers:\n",
      "\t\n",
      "[2021-04-21 11:59:45,018-rk0-features.py# 66] Current training 1 layers:\n",
      "\t\n"
     ]
    }
   ],
   "source": [
    "from custom import Custom\n",
    "model = Custom(anchors=cfg['anchors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e3d1e8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-04-21 11:59:45,131-rk0-load_helper.py# 31] load pretrained model from /projectnb/ece601/cliao25/SiamMask/experiments/siammask_base/snapshot/checkpoint_e15.pth\n",
      "[2021-04-21 11:59:45,655-rk0-load_helper.py# 25] remove prefix 'module.'\n",
      "[2021-04-21 11:59:45,657-rk0-load_helper.py# 18] used keys:324\n"
     ]
    }
   ],
   "source": [
    "assert isfile(args.resume), '{} is not a valid file'.format(args.resume)\n",
    "model = load_pretrain(model, args.resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "51ab858b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "device = torch.device('cuda' if (torch.cuda.is_available() and not args.cpu) else 'cpu')\n",
    "model = model.to(device)\n",
    "# setup dataset\n",
    "dataset = load_dataset(args.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "86f1f1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vos_enable = False\n",
    "total_lost = 0  # VOT\n",
    "iou_lists = []  # VOS\n",
    "speed_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "89185c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-04-21 11:59:48,450-rk0-<ipython-input-58-d17cd02ca5bf>#  4] Namespace(arch='Custom', config='/projectnb/ece601/cliao25/SiamMask/experiments/siammask_base/config.json', cpu=False, dataset='VOT2018', debug=False, gt=False, log='log_test.txt', mask=True, refine=False, resume='/projectnb/ece601/cliao25/SiamMask/experiments/siammask_base/snapshot/checkpoint_e15.pth', save_mask=False, video='', visualization=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['ants1', 'ants3', 'bag', 'ball1', 'ball2', 'basketball', 'birds1', 'blanket', 'bmx', 'bolt1', 'bolt2', 'book', 'butterfly', 'car1', 'conduction1', 'crabs1', 'crossing', 'dinosaur', 'drone_across', 'drone_flip', 'drone1', 'fernando', 'fish1', 'fish2', 'fish3', 'flamingo1', 'frisbee', 'girl', 'glove', 'godfather', 'graduate', 'gymnastics1', 'gymnastics2', 'gymnastics3', 'hand', 'handball1', 'handball2', 'helicopter', 'iceskater1', 'iceskater2', 'leaves', 'matrix', 'motocross1', 'motocross2', 'nature', 'pedestrian1', 'rabbit', 'racing', 'road', 'shaking', 'sheep', 'singer2', 'singer3', 'soccer1', 'soccer2', 'soldier', 'tiger', 'traffic', 'wiper', 'zebrafish1'])\n"
     ]
    }
   ],
   "source": [
    "print(dataset.keys())\n",
    "init_log('global', logging.INFO)\n",
    "logger = logging.getLogger('global')\n",
    "logger.info(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fa942b2d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-1d7849dfb967>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     lost, speed = track_vot(model, dataset[video], cfg['hp'] if 'hp' in cfg.keys() else None,\n\u001b[0;32m---> 10\u001b[0;31m                      args.mask, args.refine, device=device)\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mtotal_lost\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mspeed_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-97-a0436feda163>\u001b[0m in \u001b[0;36mtrack_vot\u001b[0;34m(model, video, hp, mask_enable, refine_enable, device)\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mregions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'VOT'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart_frame\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m                 \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msiamese_track\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_enable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefine_enable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# track\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask_enable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m                     \u001b[0mlocation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ploygon'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-97-a0436feda163>\u001b[0m in \u001b[0;36msiamese_track\u001b[0;34m(state, im, i, mask_enable, refine_enable, device, debug)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmask_enable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_crop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_crop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/siammask/experiments/siammask_base/custom.py\u001b[0m in \u001b[0;36mtrack_mask\u001b[0;34m(self, search)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrack_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0msearch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0mrpn_pred_cls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrpn_pred_loc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mpred_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projectnb/ece601/cliao25/SiamMask/.conda/siammask/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/siammask/experiments/siammask_base/custom.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mp3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mp3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projectnb/ece601/cliao25/SiamMask/.conda/siammask/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/siammask/experiments/siammask_base/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;31m# print x.size()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0mp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0mp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0mp3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projectnb/ece601/cliao25/SiamMask/.conda/siammask/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projectnb/ece601/cliao25/SiamMask/.conda/siammask/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projectnb/ece601/cliao25/SiamMask/.conda/siammask/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/siammask/experiments/siammask_base/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projectnb/ece601/cliao25/SiamMask/.conda/siammask/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projectnb/ece601/cliao25/SiamMask/.conda/siammask/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 301\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "v_id = 0\n",
    "video = 'nature'\n",
    "\n",
    "if vos_enable:\n",
    "    iou_list, speed = track_vos(model, dataset[video], cfg['hp'] if 'hp' in cfg.keys() else None,\n",
    "                         args.mask, args.refine, args.dataset in ['DAVIS2017', 'ytb_vos'], device=device)\n",
    "    iou_lists.append(iou_list)\n",
    "else:\n",
    "    lost, speed = track_vot(model, dataset[video], cfg['hp'] if 'hp' in cfg.keys() else None,\n",
    "                     args.mask, args.refine, device=device)\n",
    "    total_lost += lost\n",
    "speed_list.append(speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ecb2a624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00083483, 0.00155876, 0.00053967, ..., 0.00017562, 0.00024404,\n",
       "       0.00031803])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c0c1e57c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2187"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(HH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ca9c2cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2187"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HH.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dc1e929b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1, -2, -3, -4, -5, -6, -7, -8, -9]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in range(-1,-10,-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3d0add",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
